# Wiki Web Crawler.py
A python WebCrawler that crawls a random wikipedia page and open the first link. Then on that page it chooses the first link in the main body of the article text and it keeps going. There is a common saying that if you kept clicking on the first link you will land to the 'Philosophy' page as it's the mother of all descendants topics. This script tries to automate it using web crawling.

# Bike Share Analysis.ipynb
Over the past decade, bicycle-sharing systems have been growing in number and popularity in cities across the world. Bicycle-sharing systems allow users to rent bicycles for short trips, typically 30 minutes or less. Thanks to the rise in information technologies, it is easy for a user of the system to access a dock within the system to unlock or return bicycles. These technologies also provide a wealth of data that can be used to explore how these bike-sharing systems are used. I used Python to clean the data, compute descriptive statistics, and create basic visualizations of the distribution of data.

# Investigate a Dataset - TMDb.ipynb

The aim of the project is to investigate a dataset using Python along with external libraries and tools such as Anacondas, Pandas, NumPy and Matplotlib.
This data set contains information about 10,000 movies collected from The Movie Database (TMDb), including user ratings and revenue, while lacking profit which will be created. The Dataset features the movie name, vote score, vote count, genre, director, cast, revenue and budget along with other information.

# Data Wrangling.ipynb

Real-world data problems as it rarely comes clean and structured. The aim of the project is to adhere and go through these issues, which will involve three phases of gathering data from different sources, assessing data quality and tidiness and finally cleaning them. The project will introduce practices like web scrapping via external tools and APIs such as tweepy and downloading files programmatically

# Poblem solving.py

A set of problem solving that I solved using python as refresher/revision.

# ODK_Briefcase_missing_submissions_walker.py

A python scripts that traverses through directories identifying whether a directory is missing a specific files or not. These directories are generated by *`ODK Briefcase`*. It is an open source tool that pulls data from online forms. Data is pulled for each form's submission/entry filled by the user in such form. Each entry should have a one directory hosting two files a data file and encryption key. The script identifies troubled submissions that have missing encryption keys and moves them to another staging area as this prevents extracting the whole form data.
